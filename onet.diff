diff --git a/local.go b/local.go
index a8316e4..7a7904b 100644
--- a/local.go
+++ b/local.go
@@ -269,7 +269,6 @@ func (l *LocalTest) CloseAll() {
 	if l.T != nil && l.T.Failed() {
 		return
 	}
-
 	InformAllServersStopped()
 
 	// If the debug-level is 0, we copy all errors to a buffer that
@@ -278,6 +277,25 @@ func (l *LocalTest) CloseAll() {
 		log.OutputToBuf()
 	}
 
+	// For all services that have `TestClose` defined, call it to make
+	// sure they are able to clean up. This should only be used for tests!
+	var wg sync.WaitGroup
+	for _, srv := range l.Servers {
+		srv.serviceManager.servicesMutex.Lock()
+		for _, serv := range srv.serviceManager.services {
+			wg.Add(1)
+			go func(s Service) {
+				defer wg.Done()
+				c, ok := s.(TestClose)
+				if ok {
+					c.TestClose()
+				}
+			}(serv)
+		}
+		srv.serviceManager.servicesMutex.Unlock()
+	}
+	wg.Wait()
+
 	if err := l.WaitDone(5 * time.Second); err != nil {
 		switch l.Check {
 		case CheckNone:
diff --git a/overlay.go b/overlay.go
index 8d8e480..e3e8e7f 100644
--- a/overlay.go
+++ b/overlay.go
@@ -158,6 +158,9 @@ func (o *Overlay) TransmitMsg(onetMsg *ProtocolMsg, io MessageProxy) error {
 		// request the PI from the Service and binds the two
 		pi, err = o.server.serviceManager.newProtocol(tni, config)
 		if err != nil {
+			o.instancesLock.Lock()
+			o.nodeDelete(onetMsg.To)
+			o.instancesLock.Unlock()
 			return err
 		}
 		if pi == nil {
diff --git a/server.go b/server.go
index 5151248..ab73ee5 100644
--- a/server.go
+++ b/server.go
@@ -159,29 +159,16 @@ func (c *Server) Close() error {
 	}
 	c.Unlock()
 
-	// For all services that have `TestClose` defined, call it to make
-	// sure they are able to clean up. This should only be used for tests!
-	c.serviceManager.servicesMutex.Lock()
-	var wg sync.WaitGroup
-	for _, serv := range c.serviceManager.services {
-		wg.Add(1)
-		go func(s Service) {
-			defer wg.Done()
-			c, ok := s.(TestClose)
-			if ok {
-				c.TestClose()
-			}
-		}(serv)
+	err := c.Router.Stop()
+	if err != nil {
+		log.Error("While stopping router:", err)
 	}
-	c.serviceManager.servicesMutex.Unlock()
-	wg.Wait()
 	c.WebSocket.stop()
 	c.overlay.Close()
-	err := c.serviceManager.closeDatabase()
+	err = c.serviceManager.closeDatabase()
 	if err != nil {
 		log.Lvl3("Error closing database: " + err.Error())
 	}
-	err = c.Router.Stop()
 	log.Lvl3("Host Close", c.ServerIdentity.Address, "listening?", c.Router.Listening())
 	return err
 }
diff --git a/service.go b/service.go
index 88784f5..d95b4d3 100644
--- a/service.go
+++ b/service.go
@@ -426,6 +426,10 @@ func (s *serviceManager) serviceByID(id ServiceID) (Service, bool) {
 // the creation of the PI. Otherwise the service is responsible for setting up
 // the PI.
 func (s *serviceManager) newProtocol(tni *TreeNodeInstance, config *GenericConfig) (pi ProtocolInstance, err error) {
+	if s.server.Closed() {
+		err = errors.New("will not pass protocol once the server is closed")
+		return
+	}
 	si, ok := s.serviceByID(tni.Token().ServiceID)
 	defaultHandle := func() (ProtocolInstance, error) { return s.server.protocolInstantiate(tni.Token().ProtoID, tni) }
 	if !ok {
diff --git a/treenode.go b/treenode.go
index 549d351..0dc8c20 100644
--- a/treenode.go
+++ b/treenode.go
@@ -338,6 +338,12 @@ func (n *TreeNodeInstance) Shutdown() error {
 
 // closeDispatch shuts down the go-routine and calls the protocolInstance-shutdown
 func (n *TreeNodeInstance) closeDispatch() error {
+	defer func() {
+		if r := recover(); r != nil {
+			log.Print("Recovered in f", r)
+			log.Print(log.Stack())
+		}
+	}()
 	log.Lvl3("Closing node", n.Info())
 	n.msgDispatchQueueMutex.Lock()
 	n.closing = true
